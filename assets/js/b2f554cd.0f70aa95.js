"use strict";(self.webpackChunkcyclops_ui_docs=self.webpackChunkcyclops_ui_docs||[]).push([[1477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/2024/01/29/OCI-based-registries","metadata":{"permalink":"/blog/2024/01/29/OCI-based-registries","source":"@site/blog/2024-01-29-OCI-based-registries/index.md","title":"Coexistence of containers and Helm charts - OCI based registries","description":"Docker Ship","date":"2024-01-29T00:00:00.000Z","formattedDate":"January 29, 2024","tags":[],"readingTime":9.52,"hasTruncateMarker":false,"authors":[{"name":"Juraj Karad\u017ea","title":"Cyclops CEO","url":"https://github.com/KaradzaJuraj","imageURL":"https://github.com/KaradzaJuraj.png","key":"jurajk"}],"frontMatter":{"title":"Coexistence of containers and Helm charts - OCI based registries","authors":["jurajk"]},"unlisted":false,"nextItem":{"title":"\ud83c\udf80 Five tools to make your K8s experience more enjoyable \ud83c\udf80","permalink":"/blog/2024/01/15/five-kubernetes-UIs"}},"content":"![Docker Ship](../../static/img/2024-01-29-OCI-based-registries/oci_helm_docker.jpeg)\\n\\nIf you are using Kubernetes, there\'s a fair chance you are using Helm or at least considered to. This article will guide you on how to publish your Helm charts in a less conventional way - using OCI-based registries.\\n\\nFirst of all, we will briefly cover what OCI-based registries are and how they can help us, and after some theory, we will create a Helm chart, push it to the OCI registry, and actually deploy something using it.\\n\\n### Show us your support \ud83d\ude4f\ud83c\udffb\\n\\n<div style={{\\"text-align\\": \\"center\\"}}>\\n  ![ProductHunt Launch](../../static/img/product-hunt.gif)\\n</div>\\n\\nBefore we start, we want to mention that we scheduled our[first release on Product Hunt](https://www.producthunt.com/products/cyclops)! Click the notify me button to be alerted when we are out and ready to receive your feedback \ud83d\udd14\\n\\nWe would love it if you starred our [repository](https://github.com/cyclops-ui/cyclops) and helped us get our tool in front of other developers \u2b50\\n\\n# Helm OCI-based registries\\n\\nHelm repositories are used to store Helm charts. Using them, we can publish and version our applications as packaged Helm charts others can install into their cluster. They also allow for easier versioning and rollback of resources. All in all, a single, centralized place to store your Helm charts.\\n\\nUnder the hood, a Helm repository is a simple HTTP server that serves an `index.yaml` file that contains information about charts stored in that repository, like versions, descriptions, and URLs on where to download chart contents (usually on the same server). Read more about `index.yaml` file [here](https://helm.sh/docs/topics/chart_repository/#the-index-file).\\n\\nOCI stands for [Open Container Initiative](https://opencontainers.org/), and its goal as an organization is to define a specification for container formats and runtime.\\n\\nAt first glance, it does not seem related to the Helm repositories we just mentioned; at least for me it wasn\u2019t. OCI registries mostly host container images, but we can store different types of content there. One of the types we can host is Helm charts!\\n\\nWith such a registry, you can host all your images and Helm charts in the same place. On top of that, you don\u2019t need to maintain a Helm repository `index.yaml` file, which makes the management of your chart easier.\\n\\nYou can serve the exact same chart on a Helm repository and a container (OCI) registry; the only difference between those two approaches is how you maintain the charts.\\n\\nYou can use multiple different container registries to store Helm charts:\\n\\n- [Amazon ECR](https://docs.aws.amazon.com/AmazonECR/latest/userguide/push-oci-artifact.html)\\n- [Azure Container Registry](https://docs.microsoft.com/azure/container-registry/container-registry-helm-repos#push-chart-to-registry-as-oci-artifact)\\n- [Docker Hub](https://docs.docker.com/docker-hub/oci-artifacts/) (used in this demo)\\n- [Google Artifact Registry](https://cloud.google.com/artifact-registry/docs/helm/manage-charts)\\n- [Harbor](https://goharbor.io/docs/main/administration/user-defined-oci-artifact/)\\n- [IBM Cloud Container Registry](https://cloud.ibm.com/docs/Registry?topic=Registry-registry_helm_charts)\\n- [JFrog Artifactory](https://www.jfrog.com/confluence/display/JFROG/Docker+Registry)\\n\\n# Getting our hands dirty\\n\\nNow that we have our basics down, let\'s see those OCI charts in practice and use them to deploy our applications. We will create a chart, push it to DockerHub, and then use it to deploy our apps in a Kubernetes cluster. In order to deploy resources from the chart we defined into a Kubernetes cluster, we are going to use Cyclops.\\n\\n## Creating a Helm chart on OCI registry\\n\\nFirstly, we are going to create a Helm chart. To create a chart, create a new directory\\n\\n```bash\\nmkdir oci-demo\\n```\\n\\nand add the files listed below to the created directory. Feel free to customize the chart to fit your needs, but for the sake of this demo, we are going to create a basic one with the following structure:\\n\\n```\\n.\\n\u2514\u2500\u2500 oci-demo\\n    \u251c\u2500\u2500 Chart.yaml                 # YAML file containing information about the chart\\n    \u251c\u2500\u2500 templates                  # Directory of templates that, when combined with values, will generate valid Kubernetes manifest files.\\n    \u2502         \u251c\u2500\u2500 deployment.yaml  # K8s resources are separated into multiple files. Feel free to add more or change existing\\n    \u2502         \u2514\u2500\u2500 service.yaml\\n    \u251c\u2500\u2500 values.schema.json         # JSON Schema for imposing a structure on the values.yaml file\\n    \u2514\u2500\u2500 values.yaml                # The default configuration values for this chart\\n```\\n\\nYou can find out more about each of those files/directories on Helm\'s [official docs](https://helm.sh/docs/topics/charts/).\\n\\n### Chart.yaml\\n\\nLet\'s start with [`Chart.yaml`](https://helm.sh/docs/topics/charts/#the-chartyaml-file):\\n\\n```yaml\\n# Chart.yaml\\n\\napiVersion: v1\\nname: oci-demo\\nversion: 0.0.0\\n```\\n\\nNot to go into detail, I\'m going to `302` you to the Helm docs.\\n\\n### Templates folder\\n\\nThe next step is defining what Kubernetes resources our packaged application need. We define those in the `/templates` folder. As seen in the chart structure from earlier, we are going to add only a `deployment` and a `service` to our application.\\n\\nContents of those files are below:\\n\\n```yaml\\n# templates/deployment.yaml\\n\\napiVersion: apps/v1\\nkind: Deployment\\nmetadata:\\n  labels:\\n    app: {{ .Values.name }}\\n  name: {{ .Values.name }}\\nspec:\\n  replicas: {{ .Values.replicas }}\\n  selector:\\n    matchLabels:\\n      app: {{ .Values.name }}\\n  template:\\n    metadata:\\n      labels:\\n        app: {{ .Values.name }}\\n    spec:\\n      containers:\\n      - image: {{ .Values.image -}}:{{ .Values.version }}\\n        name: {{ .Values.name }}\\n        ports:\\n        - containerPort: 80\\n          name: http\\n\\n```\\n\\nand\\n\\n```yaml\\n# templates/service.yaml\\n\\n{{- if .Values.service }}\\napiVersion: v1\\nkind: Service\\nmetadata:\\n  name: {{ .Values.name }}\\n  labels:\\n    app: {{ .Values.name }}\\nspec:\\n  type: LoadBalancer\\n  ports:\\n    - port: 80\\n      targetPort: 80\\n      protocol: TCP\\n      name: http\\n  selector:\\n    app: {{ .Values.name }}\\n{{- end }}\\n\\n```\\n\\n### Values definition\\n\\nIn the `/templates` folder we defined, obviously, just the templates. It would be a good idea to define default values for those. We are going to use `values.yaml` for that:\\n\\n```yaml\\nname: demo\\nreplicas: 3\\n\\nimage: nginx\\nversion: 1.14.2\\n\\nservice: true\\n```\\n\\nThese are default values, and anybody using your chart will most probably want to change those. But what happens if someone using your chart messes up values by providing invalid data? For example, setting `replicas: two` or `service: no`. Another thing that can get messed up is the name of the value, so somebody might use `instance: 3` instead of `replicas: 3`.\\n\\nBoth of these examples seem pretty obvious and something you wouldn\u2019t mess up, but as your chart grows, so does your `values.yaml` file. A great example is the Redis chart by Bitnami. I encourage you to scroll through its [values file](https://github.com/bitnami/charts/blob/main/bitnami/redis/values.yaml). See you in a minute!\\n\\nNow that you are back, you probably understand why validating values and defining their structure makes sense. Let\u2019s do the same for our chart.\\n\\nBut first, let\u2019s define what are the rules of this validation:\\n\\n- `service` is type boolean\\n- `name`, `image` and `version` are strings\\n- `replicas` is an integer\\n- `replicas` is \u2265 0\\n- allow only certain values for `version`; let those be `1.14.1`, `1.14.2`, or `1.15.0`\\n\\nThere are quite a few rules packed for such short values file! However, having them in place gives us the confidence to deploy the chart without worrying about making mistakes.\\n\\nNow that we have those defined, our JSON schema will look like the following:\\n\\n```json\\n{\\n  \\"properties\\": {\\n    \\"name\\": {\\n      \\"description\\": \\"Application name\\",\\n      \\"type\\": \\"string\\"\\n    },\\n    \\"replicas\\": {\\n      \\"description\\": \\"Number of replicas\\",\\n      \\"type\\": \\"integer\\",\\n      \\"minimum\\": 0\\n    },\\n    \\"image\\": {\\n      \\"description\\": \\"Container Image\\",\\n      \\"type\\": \\"string\\"\\n    },\\n    \\"version\\": {\\n      \\"description\\": \\"Container image version\\",\\n      \\"type\\": \\"string\\",\\n      \\"enum\\": [\\"1.14.1\\", \\"1.14.2\\", \\"1.15.0\\"]\\n    },\\n    \\"service\\": {\\n      \\"description\\": \\"Expose your application\\",\\n      \\"type\\": \\"boolean\\"\\n    }\\n  },\\n  \\"order\\": [\\"name\\", \\"replicas\\", \\"image\\", \\"version\\", \\"service\\"],\\n  \\"title\\": \\"Values\\",\\n  \\"type\\": \\"object\\"\\n}\\n```\\n\\nYou can find more on how to write a JSON schema for a Helm chart in the [Helm docs](https://helm.sh/docs/topics/charts/#schema-files).\\n\\n### Pushing to Docker Hub\\n\\nIf you don\u2019t already have a Docker Hub account, you should create one to host your charts.\\n\\nTo push our chart to an OCI registry, we will need to package the chart into a tarball with the following command:\\n\\n```bash\\nhelm package oci-demo\\n```\\n\\nThere should now be a tarball file called `oci-demo-0.0.0.tgz` .\\n\\nNext, you will need to sign in to Docker Hub using Helm:\\n\\n```bash\\nhelm registry login registry-1.docker.io -u {username}\\n```\\n\\nAnd finally, push your chart to the remote registry:\\n\\n```bash\\nhelm push oci-demo-0.0.0.tgz oci://registry-1.docker.io/{username}\\n```\\n\\nCheck your artifacts on [Docker Hub](https://hub.docker.com/), and you should see your newly created Helm chart. If you click on the chart, you\u2019ll see more info about the chart and its versions.\\n\\n![Docker Hub tags](../../static/img/2024-01-29-OCI-based-registries/docker-hub.png)\\n\\n## Using OCI charts\\n\\nWe now have our Helm chart locked and loaded, so let\u2019s use it. First of all, let\'s spin up a Kubernetes cluster. If you already have a running Kubernetes cluster, feel free to use it and skip this step.\\n\\n### Create a minikube Cluster\\n\\nWhen I want to play around with a new Kubernetes tool, I try it out on a minikube cluster. Minikube is basically a Kubernetes cluster you can run on your own machine and easily tear down once you are done.\\n\\nIf you are using a mac, you can install it via brew:\\n\\n```bash\\nbrew install minikube\\n```\\n\\nCheck their installation guide here \u2192 https://minikube.sigs.k8s.io/docs/start/\\n\\nTo actually run the cluster, just hit:\\n\\n```bash\\nminikube start\\n```\\n\\nA quick check that everything is ok; let\'s list all the namespaces:\\n\\n```bash\\nkubectl get ns\\n\\nNAME              STATUS   AGE\\ndefault           Active   11s\\nkube-node-lease   Active   13s\\nkube-public       Active   13s\\nkube-system       Active   13s\\n```\\n\\n### Deploy OCI chart into a Kubernetes cluster\\n\\nYou can deploy your newly created Helm chart using pure Helm, but let\u2019s take it a step further. Chances are we will want to edit that deployment with our specific values and change those over time, so let\'s make it more user-friendly.\\n\\nWe can use Cyclops to help us with that! It can help you deploy and visualize your applications by giving you a simple UI where you get your chart deployed in just a couple of clicks. Let\u2019s install Cyclops into our cluster and deploy that newly created chart!\\n\\nYou can install Cyclops with a single command:\\n\\n```bash\\nkubectl apply -f https://raw.githubusercontent.com/cyclops-ui/cyclops/v0.0.1-alpha.12/install/cyclops-install.yaml\\n```\\n\\nIt will create a new namespace called `cyclops` and start a Cyclops deployment inside it.\\n\\nCheck that pods are up and running:\\n\\n```bash\\nkubectl get pods -n cyclops\\n\\nNAME                           READY   STATUS    RESTARTS   AGE\\ncyclops-ctrl-d6fd877d8-tpdqd   1/1     Running   0          62s\\ncyclops-ui-5c858b44d4-dhn2c    1/1     Running   0          62s\\n```\\n\\nOnce those are up, you need to port-forward both deployments:\\n\\n```bash\\nkubectl port-forward svc/cyclops-ui 3000:3000 -n cyclops\\n```\\n\\nand in a separate window, run:\\n\\n```bash\\nkubectl port-forward svc/cyclops-ctrl 8080:8080 -n cyclops\\n```\\n\\nYou can now access Cyclops at [http://localhost:3000](http://localhost:3000/)\\n\\nWhen you open your local Cyclops, you can hit `Add module` in the upper right corner.\\n\\nThis is where we get to use our OCI chart! You are prompted for the `repository`, `path`, and `version` of the template. You can fill those out with the OCI chart you created earlier, like I did below.\\n\\n```\\nRepository: oci://registry-1.docker.io/{username}\\nPath:       oci-demo\\nVersion:    0.0.0\\n```\\n\\nFrom here, you can just hit load and let Cyclops render a form based on your chart.\\n\\n![](../../static/img/2024-01-29-OCI-based-registries/rendered-form.png)\\n\\nDo you remember that schema file we added to our chart earlier? This is what Cyclops uses to render this form for you. All the fields and validations you set in the `values.schema.json` file are taken into account so you can get a completely custom UI for your applications.\\n\\nYou can now fill those fields out and hit save, and Cyclops will do the rest for you. Firstly, it will inject those form values into the template and then deploy each of the resources into the cluster.\\n\\n![](../../static/img/2024-01-29-OCI-based-registries/module-details.png)\\n\\n# Any last words?\\n\\nWe started from scratch and, in a couple of minutes, deployed an application with our own Helm chart and a custom UI tailored specifically for our application. On top of that, we did it using an OCI-based registry and didn\u2019t go through setting up a Helm repository to serve our chart.\\n\\nHope you had fun throughout the article and found the information and steps we did useful. Thank you for checking out our article!"},{"id":"/2024/01/15/five-kubernetes-UIs","metadata":{"permalink":"/blog/2024/01/15/five-kubernetes-UIs","source":"@site/blog/2024-01-15-five-kubernetes-UIs/index.md","title":"\ud83c\udf80 Five tools to make your K8s experience more enjoyable \ud83c\udf80","description":"Kubernetes Enjoyer","date":"2024-01-15T00:00:00.000Z","formattedDate":"January 15, 2024","tags":[],"readingTime":6.78,"hasTruncateMarker":false,"authors":[{"name":"Juraj Karad\u017ea","title":"Cyclops CEO","url":"https://github.com/KaradzaJuraj","imageURL":"https://github.com/KaradzaJuraj.png","key":"jurajk"}],"frontMatter":{"title":"\ud83c\udf80 Five tools to make your K8s experience more enjoyable \ud83c\udf80","authors":["jurajk"]},"unlisted":false,"prevItem":{"title":"Coexistence of containers and Helm charts - OCI based registries","permalink":"/blog/2024/01/29/OCI-based-registries"},"nextItem":{"title":"Kubernetes Made Simple - Introducing Cyclops","permalink":"/blog/2024/1/3/cyclops-overview"}},"content":"![Kubernetes Enjoyer](../../static/img/2024-01-15-five-kubernetes-UIs/kubernetes_enjojyer.png)\\n\\nFor the uninitiated, **K8s stands for Kubernetes**, with the number 8 representing the eight letters between **K** and \\n**s.** Kubernetes has become pretty much unavoidable in the current tech landscape but remains uninviting because of its \\ncomplexity and steep learning curve.\\n\\nThe terminal-based interaction has a part to play in this story. If you ever had the privilege of watching a seasoned \\nDevOps work his way with a Kubernetes cluster, you might look at him like you would a seasoned martial artist showcasing \\nhis fighting skills. That is because everything that is done through a terminal always looks more frightening and seems \\nlike it requires years and years of training. \ud83e\udd4b\\n\\nNow the question stands: how can we make such a complex issue (one that even had its name beautified) more enjoyable? \\nWell, in the same way we make everything more enjoyable \u2192 make it easier and make it prettier! \ud83c\udf80 And how would you do \\nthat, you might ask. With a **graphical user interface,** or GUI for short! Let\u2019s take a look at **five tools** that \\nprovide you with a user interface when dealing with Kubernetes.\\n\\n### Show us your support \ud83d\ude4f\ud83c\udffb\\n![ProductHunt Launch](../../static/img/product-hunt.gif)\\n\\nBefore we start, we want to mention that we scheduled our \\n[first release on Product Hunt](https://www.producthunt.com/products/cyclops)! Click the notify me button to be alerted \\nwhen we are out and ready to receive your feedback \ud83d\udd14\\n\\nAnd we would love it if you starred our [repository](https://github.com/cyclops-ui/cyclops ) and helped us get our tool \\nin front of other developers \u2b50\\n\\n\\n## Kubernetes Dashboard\\n\\nLet\'s dive into the **quintessential tool for Kubernetes management** \u2013 \\n[**the Kubernetes Dashboard**](https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/). Automatically bundled with \\nyour cluster, it delivers a graphical overview of your Kubernetes environment. You can use it to get an overview of \\napplications running on a cluster, deploy containerized applications to a Kubernetes cluster, and manage cluster \\nresources.\\n\\nThe Kubernetes Dashboard not only offers an overview but also helps with troubleshooting. It provides insights into the\\n health of Kubernetes resources, spotlighting any operational errors.\\n\\nThrough it, you can deploy applications as well. You can do it with a manifest that you wrote or through a form that you \\njust fill in. However, it\'s worth noting that the form, while user-friendly, lacks the flexibility for customization \\nbeyond basic examples.\\n\\nWhile the K8s dashboard is a **jack-of-all-trades**, many find it to be a generalist, lacking in-depth features. This \\nlimitation encourages us to explore more tools, each designed for specific purposes, and so we embark on our journey \\nthrough the list of tools we\u2019ve explored.\\n\\n![K8s Dashboard](../../static/img/2024-01-15-five-kubernetes-UIs/k8s-dashboard.png)\\n\\n\\n## K9s\\n\\n[**K9s**](https://k9scli.io/) is your best friend (get it? \ud83d\udc36) when exploring your cluster via the terminal. It shares commonality with Vim \\nfor its interaction style using shortcuts and starting commands with`:` but don\u2019t let that discourage you. K9s keeps a \\nvigilant eye on Kubernetes activities, providing **real-time** information and intuitive commands for resource \\ninteraction.\\n\\nIt can almost replace the standard `kubectl` and doesn\u2019t require you to have a \u201ccheat sheet\u201d next to you when \\ninteracting with Kubernetes. You traverse through your resources just by selecting them and drilling down to the lowest \\nlevel. This allows for easy log extraction and access to its shell.\\n\\nK9s gives you the ability to see the manifest of each of your resources and the ability to edit and apply changes. As I \\nmentioned, it **almost** replaces the `kubectl`. One of the differentiators is that you **cannot** deploy new resources \\nvia the K9s.\\n\\nK9s comes with the ability to filter out your resources and search them with the `/` command, making it easier to locate \\nthe ones you are looking for in the sea of resources or filter through the logs of a specific pod.\\n\\nA nice touch is the list of commands and shortcuts available to you at any given moment at the top of the screen, and \\nits customization with skins and plugins gives you room for additional utility.\\n\\n![K9s UI](../../static/img/2024-01-15-five-kubernetes-UIs/k9s-ui.png)\\n\\n\\n## Cyclops\\n\\nIf you are having difficulties fighting with manifest files, [**Cyclops**](https://cyclops-ui.com/) is the tool for you! \\nCyclops removes the clutter and complexity when dealing with manifests by transforming them into a structured web-based \\nform, eliminating the need for manual configuration and command-line interactions.\\n\\nThis makes the deployment process **more accessible** to individuals with varying levels of technical expertise.\\n\\nWithin the architecture of Cyclops, a central component is the [Helm](https://helm.sh/) engine. Helm is very \\npopular within the Kubernetes community; chances are you have already run into it. The popularity of Helm plays to \\nCyclops\'s strength because of its straightforward integration.\\n\\n![Cyclops Form](../../static/img/2024-01-15-five-kubernetes-UIs/cyclops-form.png)\\n\\nWith Cyclops, you\'re not boxed into a one-size-fits-all approach. **You can customize the form to suit your unique \\nneeds.** For instance, a team member can generate a Helm chart, allowing others to define necessary values using \\nCyclops for painless application deployment.\\n\\nOnce you have declared the wanted state of your application, deploying it is as straightforward as clicking a button. \\nFurthermore, once you deploy your application, the wanted state is also easily changeable through Cyclops.\\n\\nIn Cyclops, every application lays out a detailed list of resources it uses - deployments, services, pods, and others, \\nall in plain view. You can easily track their status, helping you quickly spot and fix any hiccups in your application. \\nIt\'s like having a clear roadmap to navigate and troubleshoot any issues that pop up.\\n\\n![Cyclops Resources](../../static/img/2024-01-15-five-kubernetes-UIs/cyclops-resources.png)\\n\\n\\n## DevSpace\\n\\nConsider the convenience and time saving of your local server refreshing automatically with every code save, providing \\nreal-time visualization of your code changes.\\n\\nImagine taking this smooth experience a step further into Kubernetes clusters; [**DevSpace**](https://www.devspace.sh/) \\nmakes that possible. With DevSpace, you can **deploy applications in real time** during the coding process, facilitating \\nswift iteration.\\n\\nDevSpace streamlines the process by automatically applying changes to your K8s cluster without needing the entire image \\nbuilding and deployment pipeline. It builds the image locally without pushing it to a registry, although the option to \\nautomatically push images is available for those who require it during development.\\n\\nMoreover, DevSpace features a user interface that, while somewhat limited, offers a quick overview of all pods in your \\ncluster. It allows you to **easily access pod logs and even execute commands** directly within them, enhancing your \\ndevelopment workflow.\\n\\nAlthough I have focused on local development, DevSpace is used for creating workflows as well. All your workflows are \\nsaved in one file, making it easy to reproduce environments on any machine with a single `devspace deploy` command.\\n\\n![DevSpace UI](../../static/img/2024-01-15-five-kubernetes-UIs/devspace-ui.png)\\n\\n\\n## Kubevious\\n\\nUnlike the other tools mentioned in this post, [**Kubevious**](https://kubevious.io/) has no way of changing the cluster \\nstate. It is intended solely as an observability tool, focusing on potential issues in your cluster. It highlights \\npotential threats and risks for every resource you may run.\\n\\nThe graphical views offer insights into containers, networking, exposure, RBAC, and Helm charts for intuitive \\ntroubleshooting.\\n\\nKubevious has a **rule engine** that helps with the detection and prevention of misconfigurations. It comes with rules \\nout of the box, but it allows you to create custom rules as well (for example, \u201cdon\u2019t allow images to be on the \\n*latest* tag\u201d).\\n\\nIt also comes with the cool **time machine** feature that allows users to travel back in time, audit applications, root \\ncause outages, and recover manifests, ensuring a complete understanding of cluster history.\\n\\nAnd I have to mention the **full-text** search it provides! You can search for any resource without knowing the specific \\nname of it. One great example is searching for any resources that use a specific port by just typing in \u201c*port 3000*,\u201d \\nand Kubevious will find your resource.\\n\\n![Kubevious Dashboard](../../static/img/2024-01-15-five-kubernetes-UIs/kubevious-dashboard.png)\\n\\n\\n## Final thoughts\\n\\nIn our quest to enhance the Kubernetes experience, we\'ve unwrapped five delightful tools, each offering its unique charm \\n to make your journey smoother and more enjoyable.\\n\\nThese are not the only tools that provide a UI for Kubernetes, but we wanted to shine a spotlight on some, maybe \\nlesser-known ones.\\n\\nAll of these tools are open-source, so give them a go; they\'re free!\\n\\nI want to end this post with a question directed to you, the reader: What are your thoughts on graphical representations \\nof Kubernetes? Is it needed, or does `kubectl` reign supreme?"},{"id":"/2024/1/3/cyclops-overview","metadata":{"permalink":"/blog/2024/1/3/cyclops-overview","source":"@site/blog/2024-1-3-cyclops-overview/index.md","title":"Kubernetes Made Simple - Introducing Cyclops","description":"Modules in Cyclops","date":"2024-01-03T00:00:00.000Z","formattedDate":"January 3, 2024","tags":[],"readingTime":6.805,"hasTruncateMarker":false,"authors":[{"name":"Juraj Karad\u017ea","title":"Cyclops CEO","url":"https://github.com/KaradzaJuraj","imageURL":"https://github.com/KaradzaJuraj.png","key":"jurajk"}],"frontMatter":{"title":"Kubernetes Made Simple - Introducing Cyclops","authors":["jurajk"]},"unlisted":false,"prevItem":{"title":"\ud83c\udf80 Five tools to make your K8s experience more enjoyable \ud83c\udf80","permalink":"/blog/2024/01/15/five-kubernetes-UIs"},"nextItem":{"title":"Complexity by Simplicity - A Deep Dive Into Kubernetes Components","permalink":"/blog/2023/12/18/k8s-cluster-components"}},"content":"![Modules in Cyclops](../../static/img/2024-1-3-cyclops-overview/cyclops_overview_1.png)\\n\\nIf you are a developer, the chances are you have heard about Kubernetes. You heard that it is an amazing tool to help \\nyou scale your applications and manage your micro-services. But, you probably also heard that it is **VERY** complex. \\nIt is so complex that you were probably scared off. And I don\u2019t blame you; that is the first reaction I got as well.\\n\\nIf you search the top posts with the Kubernetes tags on this website, you will find a myriad of tutorials and people \\nexplaining Kubernetes. These posts are the most trending because people **WANT** to understand Kubernetes because we \\nfeel like, in today\'s software development world, Kubernetes is unavoidable. And this is true, to an extent\u2026\\n\\nSoftware developers are often required to understand and work with Kubernetes; if you have ever looked for jobs in this \\nsector, you know this already. But what if there was a tool to minimize your touching points with Kubernetes? A tool \\nthat simplifies the process and gives you guidance when trying to deploy applications into Kubernetes clusters. A tool \\nthat is highly customizable and lets someone in your organization (who understands Kubernetes, commonly known as a \\nDevOps) create a user interface for you!\\n\\nYep, you guessed it, it\u2019s Cyclops! \ud83d\ude04\\n\\nAnd just to clarify, Cyclops is not used to create and manage Kubernetes clusters and other infrastructure; rather, \\nCyclops is used for deploying and managing applications INSIDE the cluster.\\n\\n### Show us your support \ud83d\ude4f\ud83c\udffb\\n![Github Stars](../../static/img/2023-12-18-k8s-cluster-components/github_stars.gif)\\n\\nWe are building Cyclops to be **open-source**, and your support would mean the world to us. Consider giving us a star \\non [GitHub](https://github.com/cyclops-ui/cyclops) and following us on [ProductHunt](https://www.producthunt.com/products/cyclops), where we scheduled our very \\nfirst release!\\n\\n## Before we start\\n\\nIn order to test out Cyclops, you are going to need a few things. If this is not your first time using Kubernetes, the \\nchances are you already have everything ready, but we will still describe each of the components for the newcomers to \\nthe Kubernetes space. These tools are not only used for Cyclops, and you can use them for anything Kubernetes-related.\\n\\nThe main thing you are going to need to test out Cyclops is a Kubernetes cluster. If you have one that you can use to \\nplay with, great; if not, we will show you how to spin up a cluster on your own computer. So, the three prerequisites \\nfor doing this are:\\n\\n1. [**1. Docker**](https://www.docker.com/products/docker-desktop/)\\n2. [**2. Minikube**](https://minikube.sigs.k8s.io/docs/)\\n3. [**3. kubectl**](https://kubernetes.io/docs/tasks/tools/)\\n\\nDocker is the most popular containerization tool, and we will use it to download and spin up a Minikube image. \\nDownloading Docker is straightforward: go to their webpage and download the Docker Desktop application.\\n\\nMinikube plays the role of a Kubernetes cluster on your local machine. It is a great tool for developing and \\ntesting out your Kubernetes applications, and it is perfect for this scenario. You can find a guide on how to install \\nit [here](https://minikube.sigs.k8s.io/docs/start/).\\n\\nThe final thing missing is a way of communicating with your Kubernetes cluster, and this is done through the Kubernetes \\ncommand line tool called `kubectl`. It can be used to deploy applications, inspect and manage cluster resources, and \\nview logs. In this tutorial, we will use it to install Cyclops into our cluster on Minikube and expose its \\nfunctionality outside the cluster.\\n\\n## Installing Cyclops\\n\\nOnce you have your Kubernetes cluster ready (check the *Before We Start* section), installing Cyclops is a \\nstraightforward process. Using `kubectl`, run the following command in your terminal:\\n\\n```\\nkubectl apply -f https://raw.githubusercontent.com/cyclops-ui/cyclops/v0.0.1-alpha.5/install/cyclops-install.yaml\\n```\\n\\nIt will create a new namespace called `cyclops` and deploy everything you need for your Cyclops instance to run.\\n\\nNow, all that is left is to expose the Cyclops server outside the cluster. You will need to expose both the backend and \\nfrontend with the commands below.\\n\\nExpose frontend through:\\n\\n```\\nkubectl port-forward svc/cyclops-ui 3000:3000 -n cyclops\\n```\\n\\nAnd the backend through:\\n\\n```\\nkubectl port-forward svc/cyclops-ctrl 8080:8080 -n cyclops\\n```\\n\\nAnd that\'s it! You can now access Cyclops in your browser at [http://localhost:3000](http://localhost:3000/).\\nIf you are having trouble with the `port-forward` commands, you probably just need to wait a few of seconds after \\ninstalling Cyclops into your cluster, it can take a while to start all it\u2019s resources.\\n\\n## It\u2019s Demo Time \ud83d\udca5\\n\\nNow that you have your Cyclops instance up and running, it\u2019s time to see what it\u2019s capable of.\\n\\nYou should be greeted with an almost empty screen with no deployed modules showing. *Module* is Cyclops\u2019s slang for \\napplication \ud83d\ude0e. So, let\u2019s start by creating our first module!\\n\\nBy clicking on the *Add module* button in the top right corner, you should be taken to a new screen. Here, Cyclops asks \\nus which Helm chart do we want to deploy.\\n\\nNot to go too deep, but [Helm](https://helm.sh/) is a very popular open-source package manager for Kubernetes. It helps \\nyou create configuration files that are needed for applications running in Kubernetes. These charts let Kubernetes know \\nhow to handle your application in the cluster.\\n\\nDon\u2019t worry; to showcase the basics of Cyclops, we created a simple Helm chart so that anyone can follow along. You can \\nfind what it looks like in our [GitHub repository](https://github.com/cyclops-ui/templates/tree/main/demo), along with \\na couple of more examples of Helm charts that you can use!\\n\\n![Loaded Chart](../../static/img/2024-1-3-cyclops-overview/cyclops_overview_2.png)\\n\\nAs you can see, once you enter the repository of your chart, Cyclops will render a user interface.  *If you want to \\nfind out the magic behind the rendering, check out our previous \\n[blog](https://dev.to/cyclops-ui/how-cyclops-utilizes-json-schema-to-deliver-dynamical-ui-49e).*\\n\\nYou can fill out the fields as you wish, but be mindful of \\n[the Kubernetes naming conventions](https://kubernetes.io/docs/concepts/overview/working-with-objects/names/)!\\n\\nIf you want to follow along, my input is as follows:\\n\\n```\\nname: demo\\nreplicas: 1\\nimage: nginx\\nversion: 1.14.2\\nservice: true\\n```\\n\\nWe will set the module name to `demo` as well. Click save, and Cyclops will show you the details of your new module.\\n\\n![Single pod Deployment](../../static/img/2024-1-3-cyclops-overview/cyclops_overview_3.png)\\n\\nThis screen shows you all the resources your application is using at the moment. It will list all the deployments, \\nservices, pods, or any other resource. Here, we can see that Cyclops deployed one pod into your cluster, as we specified \\nin the replicas field. If you want to make sure that it really is running in your cluster, you can check it out by using \\nthe following `kubectl` command:\\n\\n```\\nkubectl get pods\\n```\\n\\nBut what if all of a sudden, there was a need to scale up your application or any other resource? Well, don\'t worry; \\nwith Cyclops, it\u2019s really easy!\\n\\nBy clicking the *Edit* button, you can change the values of your application\u2019s resources. Let\u2019s try to scale our \\napplication up to 3 replicas and see what happens.\\n\\n![Three pod Deployment](../../static/img/2024-1-3-cyclops-overview/cyclops_overview_4.png)\\n\\nYou should now see two more pods in the *Deployment* tab; hurray! \ud83c\udf89\\n\\nOf course, this works for any other change you might want to make to your application. Like, the service, perhaps? What \\nif we realized we don\'t really need it anymore? Well, with Cyclops, it\'s really easy to shut it down if need be.\\n\\nClick again on the *Edit* button, and this time, turn off the service toggle.\\n\\n![Service shut down](../../static/img/2024-1-3-cyclops-overview/cyclops_overview_5.png)\\n\\nCyclops won\'t delete it automatically but will warn you (via the warning triangle sign) that you shut it down, and it is \\nnot in function anymore. This means you can safely delete it!\\n\\nAnd if you are sick and tired of your application, you can delete the whole thing as well \ud83d\uddd1\ufe0f\\n\\nClick on the Delete button and fill in the name of the module to safely delete it. You can, again, check if it really \\nwas deleted with `kubectl`:\\n\\n```\\nkubectl get pods\\n```\\n\\n## Finish\\n\\nAnd that\u2019s all there really is to it! Cyclops allows people with varying knowledge of Kubernetes to leverage its power. \\nIf you followed this tutorial, you should have deployed your very first application using Cyclops; congratz! \ud83c\udf89 On our \\n[webpage](https://cyclops-ui.com/), you can find one more tutorial showcasing more features and a more complicated use \\ncase, as well as our contact and community info.\\n\\nIf you have any sort of feedback or ideas on how to make Cyclops better, you can fill out our short \\n[Google form](https://forms.gle/jrwcBHRtpwmK91v47)!"},{"id":"/2023/12/18/k8s-cluster-components","metadata":{"permalink":"/blog/2023/12/18/k8s-cluster-components","source":"@site/blog/2023-12-18-k8s-cluster-components/index.md","title":"Complexity by Simplicity - A Deep Dive Into Kubernetes Components","description":"Image of a Kubernetes cluster based on an image found on https://kubernetes.io/docs/concepts/overview/components/","date":"2023-12-18T00:00:00.000Z","formattedDate":"December 18, 2023","tags":[],"readingTime":8.34,"hasTruncateMarker":false,"authors":[{"name":"Juraj Karad\u017ea","title":"Cyclops CEO","url":"https://github.com/KaradzaJuraj","imageURL":"https://github.com/KaradzaJuraj.png","key":"jurajk"}],"frontMatter":{"title":"Complexity by Simplicity - A Deep Dive Into Kubernetes Components","authors":["jurajk"]},"unlisted":false,"prevItem":{"title":"Kubernetes Made Simple - Introducing Cyclops","permalink":"/blog/2024/1/3/cyclops-overview"},"nextItem":{"title":"Five Kubernetes Development Tools for Efficient Cluster Management","permalink":"/blog/2023/12/08/five-kubernetes-tools"}},"content":"![Image of a Kubernetes cluster based on an image found on https://kubernetes.io/docs/concepts/overview/components/](../../static/img/2023-12-18-k8s-cluster-components/k8s_cluster.png)\\n\\n# Intro\\n\\nA couple of days ago, I held a talk about Kubernetes and its components at the college I used to go to. My mom said she liked the talk, so I turned it into a blog post.\\n\\nMany software engineers tend to look away from anything related to Kubernetes, even though they might use it daily. At first glance, it seems complex and like a whole new world to dive into. And yeah, it is, but in this blog post, I will go over all of the main components of a Kubernetes cluster and explain what they do in an example.\\n\\nBy the end of the blog post, you won\'t be a Kubernetes expert, but you will probably get a good idea of what to look for and how to structure the chaos that Kubernetes seems to be at first.\\n\\n### **Show us your support \ud83d\ude4f\ud83c\udffb**\\n![Github Stars](../../static/img/2023-12-18-k8s-cluster-components/github_stars.gif)\\n\\nBefore we start, we would love it if you starred our repository and helped us get our tool in front of other developers. Our GitHub repo is here:\xa0https://github.com/cyclops-ui/cyclops\xa0\u2b50\\n\\n# Components\\n\\nFirst of all, we can divide a Kubernetes cluster into two parts: **control plane** and **worker nodes**. The control plane takes care of the whole operation and controls the state of our cluster. We\u2019ll get into what that means shortly. On the other side, our worker nodes are essentially just computers listening to what the control plane tells them to do. They are the computing power of our cluster. Any application we run in the cluster will run on those nodes.\\n\\nLet\u2019s decompose that further.\\n\\n## Control plane\\n\\n![Control Plane](../../static/img/2023-12-18-k8s-cluster-components/control_plane.png)\\n\\nAs we said, the control plane is making sure our cluster is running as expected. It does that by communicating with the cluster user, scheduling workloads, managing cluster state and so on.\\n\\nThe control plane is made of four crucial components. Simple by themselves, but together, they create a complex system. These components are: \\n\\n1. **1. API**\\n2. **2. ETCD**\\n3. **3. Scheduler**\\n4. **4. Controller Manager**\\n\\nControl plane components can be run on any machine in the cluster, but are usually run on a separate set of machines, often called **master nodes**. Those machines are not used to run any other container or application and are reserved for the Kubernetes control plane.\\n\\n### API\\n\\nThe Kubernetes API acts as the cluster\'s front-end interface, allowing users to interact with the cluster, define desired states, and perform operations such as creating, updating, and deleting resources.\\n\\nIt is the **only point of contact** we have with the cluster. Also, no other components are talking directly to each other, but all communication is happening **through** the API.\\n\\n### ETCD\\n\\nETCD is the API\u2019s **database**; it\'s as simple as that. When you tell Kubernetes to create a deployment, it gets stored in the ETCD alongside all the other created resources.\\n\\nOne characteristic of ETCD is that its key-value storage is organized as a filesystem. Another great feature of ETCD is that users can **subscribe** to events and get notified about changes. For example, *let me know when a new pod gets created*.\\n\\n### Scheduler\\n\\nAs the name suggests, the scheduler **decides which node a pod will run on**. It does that by a set of rules you can read in the [Kubernetes documentation](https://kubernetes.io/docs/home/). *This is what I meant when I said you won\'t be an expert, but you will know what to google :)*  \\n\\nThe Scheduler **subscribes** to all newly created pods saved in ETCD, but it can **only** talk with the API to get this update.\\n\\nWhen it catches that a pod has been created, it calculates which worker node to run it on. Once it\'s made up its mind, **the scheduler doesn\'t run anything on any machine**; it just tells the API to run the pod on a particular node.\\n\\n### Controller Manager\\n\\nThe last component from the control plane is the controller manager. We can take it as a thermostat for our cluster. Its job is to shift the current state of the cluster to the desired state.\\n\\nThis means that it will **create all the needed resources** under the hood to satisfy our needs and get our applications up and running.\\n\\nIt runs multiple controller processes subscribed to changes on the ETCD, compiled into the same binary for easier deployment. Controller managers\u2019 roles and what those controllers do will be defined more closely later in the blog.\\n\\n## Worker nodes\\n\\n![Worker nodes](../../static/img/2023-12-18-k8s-cluster-components/nodes.png)\\n\\nNow that we have concluded what manages the whole cluster, let\'s dive into where our containers are running and how that is achieved.\\n\\nThere are 3 components running on each node in a Kubernetes cluster. Of course, you can have multiple nodes in a cluster, but each needs these three components to host your applications.\\n\\nThose being:\\n\\n1. **1. container runtime**\\n2. **2. kubelet**\\n3. **3. kube proxy**\\n\\n### Container runtime\\n\\nThe component that allows Kubernetes to run containers and manages the lifecycle of a container on a node is the container runtime.\\n\\nMultiple container runtimes are supported, like [conatinerd](https://containerd.io/), [cri-o](https://cri-o.io/), or other [CRI compliant runtimes](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md).\\n\\n### Kubelet\\n\\nAnother component subscribed to pod events is Kubelet. Each time a pod is scheduled on a node, the Kubelet running on that node will hear that and start all defined containers. On top of that, Kubelet also performs health checks to ensure everything is running as expected.\\n\\n### Kube proxy\\n\\nKubeProxy in Kubernetes manages network connectivity between pods across the cluster, handling tasks like load balancing and network routing. It ensures seamless communication among pods by maintaining network rules and translating service abstractions into actionable network policies.\\n\\n# From a deployment to a running container\\n\\nNow that we have listed all of the components and their role in a Kubernetes cluster, let\'s tell a story on how a Kubernetes Deployment becomes a set of containers running on various machines across the cluster.\\n\\n## Pods, Replicasets and Deployments\\n\\nJust a quick reminder on the relation of these three: Pods, Replicasets, and Deployments.\\n\\n![Deployment components](../../static/img/2023-12-18-k8s-cluster-components/deployment_components.png)\\n\\nThe smallest unit we can deploy in a Kubernetes cluster is a **pod**. With it, we are going to define our containers.\\n\\nMost likely, we will need a couple of instances of the same application, and we can define how to replicate our pods with a **Replicaset**. It will ensure that we have the desired number of pods running by starting and terminating them.\\n\\nCool, now we have our application replicated, but we would like to roll out a new version of our application. We have to tear down existing Pods/Replicaset and create new ones. A Deployment will automate this process, allowing us to roll out our feature safely.\\n\\n## The Prestige\\n\\n![Prestige](../../static/img/2023-12-18-k8s-cluster-components/prestige_gif.gif)\\n\\nNow that we have all our terminology and touched on all Kubernetes components and their role, let\'s see what happens when we \u201capply\u201d a Deployment to a Kubernetes cluster.\\n\\nLet\'s say that we have created a `deployment.yaml` file defining our application (you can see how to do that [here](https://imgur.com/7qKp189)) and ran `kubectl apply -f deployment.yaml`. `kubectl` will now submit our deployment definition to our cluster\'s **only point of contact** - the Kubernetes API.\\n\\nOur simple API will store our deployment in the ETCD database. Each time a Deployment object is saved into ETCD, it will let the API know that there was a change on Deployments and that it should let **everybody who is subscribed** to such an event know about it.\\n\\nAnd there is a component in the control plane that would like to know when a new Deployment spawns, and that\'s the **Controller Manager**. When it hears about a new Deployment, it will create a new Replicaset based on the Deployment configuration. To make this Replicaset, it will call the API with a create request.\\n\\nCreating a Replicaset is much like creating a Deployment. API will receive a Replicaset to create and store into ETCD. This will make ETCD tell the API that somebody created a Replicaset and pass that information to all subscribed components, which is **again** the Controller Manager.\\n\\nWhen the Controller Manager hears about the new Replicaset, it will create all the Pods defined with the Replicaset by, you guessed it, calling the API, which will store all those Pods into ETCD.\\n\\n![ As we said, a lot of things happened, so we decided to create a GIF that might help you understand the whole process under the hood.](../../static/img/2023-12-18-k8s-cluster-components/gif_k8s_final.gif)\\n\\n *As we said, a lot of things happened, so we decided to create a GIF that might help you understand the whole process under the hood.*\\n\\nHere, we include the Scheduler, which is subscribed to the Pod creation event. Each time it hears about a new Pod, it decides on which node it should be run. The Scheduler is not running the Pod but **only telling the API** which node it chose for it. The API will then save that information.\\n\\nAnother component listening to Pod events is the Kubelet, a component running on each worker node in the Kubernetes cluster. Each time the API tells the Kubelet that the Scheduler decided to run the Pod on its node, the Kubelet **will start all the containers** defined by the Pod.\\n\\nFinally, we turned our configuration into an application running on a machine! It is a lengthy process with many moving parts, but this may be my favorite part.\\n\\nEach component takes just a tiny bit of the responsibility of deploying an application, but they solve a pretty complex problem together.\\n\\n# Final thoughts\\n\\nHope this article helped you get a grasp on Kubernetes components and helped you demystify the most popular orchestrator out there. We encourage you to dig around yourself because we enjoyed learning about this.\\n\\nOne book we recommend to learn about Kubernetes is \u201cKubernetes in action\u201d by Marko Luk\u0161a. It is pretty popular and gives an excellent overview of what is going on under the hood of Kubernetes and how to use it."},{"id":"/2023/12/08/five-kubernetes-tools","metadata":{"permalink":"/blog/2023/12/08/five-kubernetes-tools","source":"@site/blog/2023-12-08-five-kubernetes-tools/index.md","title":"Five Kubernetes Development Tools for Efficient Cluster Management","description":"kubernetes tools","date":"2023-12-08T00:00:00.000Z","formattedDate":"December 8, 2023","tags":[],"readingTime":7.065,"hasTruncateMarker":false,"authors":[{"name":"Juraj Karad\u017ea","title":"Cyclops CEO","url":"https://github.com/KaradzaJuraj","imageURL":"https://github.com/KaradzaJuraj.png","key":"jurajk"}],"frontMatter":{"title":"Five Kubernetes Development Tools for Efficient Cluster Management","authors":["jurajk"]},"unlisted":false,"prevItem":{"title":"Complexity by Simplicity - A Deep Dive Into Kubernetes Components","permalink":"/blog/2023/12/18/k8s-cluster-components"},"nextItem":{"title":"How Cyclops utilizes JSON schema to deliver dynamical UI","permalink":"/blog/2023/11/13/JSON-schemas"}},"content":"![kubernetes tools](../../static/img/2023-12-08-five-kubernetes-tools/kubernetes_tools.png)\\n\\nKubernetes has become the go-to platform for managing containerized applications, offering scalability, flexibility, and robustness. However, the complexity of Kubernetes can be daunting, requiring developers and DevOps teams to navigate through intricate configuration files and command-line interactions. \\n\\nSeveral powerful development tools have emerged to simplify the management of Kubernetes clusters and streamline the deployment process. In this article, we will explore five Kubernetes development tools: \\n\\n1. [**1. Prometheus**](https://prometheus.io/)\\n2. [**2. Cyclops**](https://cyclops-ui.com/)\\n3. [**3. Keda**](https://keda.sh/)\\n4. [**4. Karpenter**](https://karpenter.sh/)\\n5. [**5. Velero**](https://velero.io/)\\n\\nThese tools offer intuitive user interfaces, automated scaling capabilities, disaster recovery solutions, and improved efficiency in managing Kubernetes clusters.\\n\\n### Show us your support \ud83d\ude4f\ud83c\udffb\\n\\nBefore we start, we would love it if you starred our repository and helped us get our tool in front of other developers. Our GitHub repo is here: https://github.com/cyclops-ui/cyclops \u2b50\\n\\n## 1. Prometheus: Monitoring and Alerting for Kubernetes\\n![Prometheus logo](../../static/img/2023-12-08-five-kubernetes-tools/prometheus_logo.png)\\n\\n**Prometheus** is an open-source monitoring and alerting toolkit designed specifically for microservices and containers. It offers flexible querying, real-time notifications, and visibility into containerized workloads, APIs, and distributed services. \\n\\nOne of the features of Prometheus is its ability to assist with cloud-native security by detecting irregular traffic or activity that could potentially escalate into an attack.\\n\\nIt uses a pull-based system, sending HTTP requests called \\"scrapes\\", to collect metrics from applications and services. These metrics are stored in memory and on local disk, allowing for easy retrieval and analysis.\\n\\nPrometheus can access data directly from client libraries or through exporters, which are software located adjacent to the application. Exporters accept HTTP requests from Prometheus, ensure the data format compatibility, and serve the requested data to the Prometheus server.\\n\\nPrometheus provides four main types of metrics: Counter, Gauge, Histogram, and Summary. These metrics offer flexibility in measuring various aspects of applications and services, such as event start counts, memory usage, data aggregation, and quantile ranges.\\n\\nTo discover targets for monitoring, Prometheus utilizes service discovery in Kubernetes clusters. It can access machine-level metrics separately from application information, allowing for comprehensive monitoring.\\n\\nOnce the data collection is complete, Prometheus provides a query language called PromQL, which enables users to access and export monitoring data to graphical interfaces like Grafana or send alerts using Alertmanager.\\n\\n## 2. Cyclops: Deploying applications with just a couple of clicks\\n\\n![Cyclops logo](../../static/img/2023-12-08-five-kubernetes-tools/cyclops_logo.png)\\n\\n**Cyclops** is a tool that simplifies the management of applications running in Kubernetes clusters. It abstracts complex configuration files into form-based UIs, eliminating the need for manual configuration and command-line interactions. This makes the deployment process more accessible to individuals with varying levels of technical expertise.\\n\\nWith Cyclops, you\'re not boxed into a one-size-fits-all approach. You can customize modules to suit your unique needs, giving you the freedom to create templates with input validation for seamless collaboration with your team. \\n\\nThis not only speeds up your work but also empowers each team member to work independently, promoting a smoother and more efficient workflow.\\n\\nIn Cyclops, every module lays out a detailed list of resources it uses\u2014deployments, services, pods, and others, all in plain view. You can easily track their status, helping you quickly spot and fix any hiccups in your application. It\'s like having a clear roadmap to navigate and troubleshoot any issues that pop up.\\n\\nWithin the architecture of Cyclops, a central component is the [Helm](https://helm.sh/) engine, which allows the dynamic generation of configurations. This engine serves as a key mechanism for efficiently managing settings and parameters in the Cyclops framework.\\n\\nAs Kubernetes-based systems commonly employ Helm as their package manager, seamlessly integrating Cyclops is a straightforward process.\\n\\nCyclops promotes consistency and standardization in deployment practices. By providing predefined templates or configuration presets, Cyclops ensures that deployments adhere to established best practices and guidelines. This consistency not only improves the reliability and stability of deployments but also facilitates collaboration.\\n\\n## 3. Keda: Event-Driven Autoscaling for Kubernetes Workloads\\n\\n![Keda logo](../../static/img/2023-12-08-five-kubernetes-tools/keda_logo.png)\\n\\nKubernetes Horizontal Pod Autoscaling (HPA) and Vertical Pod Autoscaling (VPA) are widely used for autoscaling Kubernetes clusters based on CPU and memory usage. \\n\\nHowever, they have limitations, such as the inability to scale pods to zero or scale based on metrics other than resource utilization. This is where **Keda** (Kubernetes Event-Driven Autoscaling) comes into play.\\n\\nKeda is an open-source container autoscaler that extends the capabilities of native Kubernetes autoscaling solutions by scaling pods based on external events or triggers.\\n\\nMonitoring event sources like AWS SQS, Kafka, and RabbitMQ, Keda efficiently triggers or halts deployments based on predefined rules. This adaptable solution also allows for custom metrics, facilitating effective autoscaling tailored for message-driven microservices, ensuring optimal performance and resource utilization.\\n\\nThe components of Keda include event sources, scalers, metrics adapters, and controllers. Event sources provide the external events that trigger scaling, while scalers monitor these events and fetch metrics. Metrics adapters translate the metrics for the controller, which then scales the deployments accordingly.\\n\\nBy leveraging Keda, DevOps teams can free up resources and reduce cloud costs by scaling down when there are no events to process. Keda also offers interoperability with various DevOps toolchains, supporting both built-in and external scalers. \\n\\nWith Keda, autoscaling becomes more flexible and efficient, empowering teams to optimize resource utilization and adapt to changing workload requirements.\\n\\n## 4. Karpenter: Automated Node Provisioning for Kubernetes\\n\\n![Karpenter logo](../../static/img/2023-12-08-five-kubernetes-tools/karpenter_logo.png)\\n\\nKubernetes clusters often face the challenge of scheduling pods on available nodes. **Karpenter** is an open-source cluster auto scaler that automatically provisions new nodes in response to un-schedulable pods. It evaluates the aggregate resource requirements of pending pods and selects the optimal instance type to accommodate them. \\n\\nKarpenter also supports a consolidation feature, actively moving pods and replacing nodes with cheaper versions to reduce cluster costs.\\n\\nA standout feature is the introduction of \\"Node Pools,\\" allowing users to categorize nodes based on various criteria. This customization ensures a tailored approach to resource allocation, with Karpenter dynamically provisioning nodes into the most fitting pools.\\n\\nAt its core, Karpenter is designed to automate the scaling of Kubernetes clusters seamlessly. Leveraging Custom Resource Definitions (CRDs) within Kubernetes, Karpenter integrates seamlessly with existing tools and APIs, providing a familiar experience for users. \\n\\nThe flexibility of Karpenter extends beyond the confines of AWS, making it a versatile solution for both cloud and on-premises environments.\\n\\nKarpenter\'s adaptability shines through its support for user-defined strategies and policies through Kubernetes resources. This flexibility enables organizations to align Karpenter with their unique application and workload requirements, enabling better automated and optimized Kubernetes scalability.\\n\\n## 5. Velero: Disaster Recovery and Backup for Kubernetes\\n![Velero logo](../../static/img/2023-12-08-five-kubernetes-tools/velero_logo.png)\\n\\n**Velero** is a powerful tool that provides disaster recovery and backup solutions for Kubernetes clusters. It enables users to easily backup, restore, and migrate applications and their persistent volumes.\\n\\nVelero takes snapshots of cluster resources and data, storing them in object storage providers like AWS S3, Google Cloud Storage, or Azure Blob Storage.\\n\\nWith Velero, users can create backup schedules, ensuring regular snapshots of critical cluster resources. This allows for efficient disaster recovery in case of data loss or cluster failures. Velero also supports cluster migration, simplifying the process of moving applications and data between Kubernetes clusters.\\n\\nThe tool offers resource filtering capabilities, allowing users to selectively backup and restore specific resources.\\n\\nThis flexibility ensures that only relevant data is included in the backup, saving storage space and reducing backup and restore times. Velero integrates with CSI (Container Storage Interface), providing support for backing up volumes and restoring them to their original state.\\n\\nIn addition to disaster recovery and backup, Velero provides features like running in any namespace, extending functionality with hooks, and supporting custom plugins for enhanced customization. It offers troubleshooting guides for diagnosing and resolving common issues, ensuring a smooth experience in managing Kubernetes clusters.\\n\\n## Conclusion\\n\\nThese five Kubernetes development tools - Prometheus, Cyclops, Keda, Karpenter, and Velero - play pivotal roles in simplifying the complexities of Kubernetes cluster management.\\n\\nFrom monitoring and alerting with Prometheus to event-driven autoscaling using Keda, and automated node provisioning through Karpenter, each tool addresses specific challenges, contributing to more efficient and resilient Kubernetes environments.\\n\\nCyclops stands out for its user-friendly approach, abstracting complex configurations into intuitive UIs, while Velero provides crucial disaster recovery and backup solutions for safeguarding critical data and applications.\\n\\nAs Kubernetes continues to be a cornerstone in modern application deployment, these tools empower developers and DevOps teams to navigate the intricacies of containerized environments with greater ease.\\n\\nBy integrating these tools into your Kubernetes workflows, you can enhance scalability, streamline deployment processes, and ensure the robustness of your applications in today\'s dynamic and demanding computing landscape."},{"id":"/2023/11/13/JSON-schemas","metadata":{"permalink":"/blog/2023/11/13/JSON-schemas","source":"@site/blog/2023-11-13-JSON-schemas/index.md","title":"How Cyclops utilizes JSON schema to deliver dynamical UI","description":"Cyclops turns complicated YAML manifests into simple and structured UIs where developers can click away their Kubernetes application configuration.","date":"2023-11-13T00:00:00.000Z","formattedDate":"November 13, 2023","tags":[],"readingTime":3.725,"hasTruncateMarker":false,"authors":[{"name":"Petar Cvitanovi\u0107","title":"Cyclops CTO","url":"https://github.com/petar-cvit","imageURL":"https://github.com/petar-cvit.png","key":"petarc"}],"frontMatter":{"title":"How Cyclops utilizes JSON schema to deliver dynamical UI","authors":["petarc"]},"unlisted":false,"prevItem":{"title":"Five Kubernetes Development Tools for Efficient Cluster Management","permalink":"/blog/2023/12/08/five-kubernetes-tools"},"nextItem":{"title":"Welcome","permalink":"/blog/welcome"}},"content":"Cyclops turns complicated YAML manifests into simple and structured UIs where developers can click away their Kubernetes application configuration.\\n\u201dGreat! But how does it know how to render this UI? Should I implement a UI form each time I need a new set of fields to configure? I don\u2019t know React! I don\u2019t know frontend!\u201c\\n\\nThis blog post should cure your anxiety about implementing a UI for each type of application and explain how Cyclops knows what to render so you can deploy to your K8s cluster carefree.\\n\\nTo better understand how Cyclops renders the UI, we will scratch the surface of Helm, which Cyclops uses as its templating engine.\\n\\n## A bit about Helm\\n\\nHelm is a Kubernetes package manager that helps deploy and manage Kubernetes resources by packing them into charts. It also has a templating engine that allows developers to configure their apps depending on the specific values injected into the helm template.\\n\\nThe usual Helm chart structure is as follows:\\n\\n```bash\\n\u251c\u2500\u2500 Chart.yaml\\n\u251c\u2500\u2500 templates\\n\u2502   \u251c\u2500\u2500 deployment.yaml\\n\u2502   \u2514\u2500\u2500 service.yaml\\n\u251c\u2500\u2500 values.schema.json\\n\u2514\u2500\u2500 values.yaml\\n```\\n\\n> A few other Helm chart parts are left out on purpose since they are not tangible to the rest of the blog. You can read more about each of those in [Helm\u2019s official documentation](https://helm.sh/docs/topics/charts/)\\n\\n- `Chart.yaml` - A YAML file containing information about the chart (like name, version\u2026)\\n- `templates` - A directory of templates that, when combined with values, will generate valid Kubernetes manifest files\\n- `values.yaml` - The default configuration values for this chart\\n- `values.schema.json` - A JSON Schema for imposing a structure on the `values.yaml` file\\n\\nWhen using Helm, you can change your `values.yaml` however you see fit for your application. The problem is that you can change them __however__ you like, which allows you to misconfigure some parts of your application because you misspelled a field or messed up indentation in the `values.yaml`.\\n\\nHere is where [JSON schema](https://json-schema.org) from the `values.schema.json` comes in. It will define which fields you should set and even to which values (e.g., you can specify that a field called replicas can\u2019t be set to lower than 0). Helm won\u2019t let you render a Kubernetes manifest with values that don\u2019t comply with the schema. There is an example of such schema later in the blog, but you can also check it out on [Helms official docs](https://helm.sh/docs/topics/charts/#schema-files)\\n\\n## Helm values schema and Cyclops UI\\n\\nNow that the schema\'s purpose in a Helm chart is explained let\u2019s get into how Cyclops uses it.\\n\\nSince the primary purpose of the values schema is to describe what the Helm chart needs to render all the Kubernetes resources, we naturally decided to use it for rendering the UI. On the first iterations of Cyclops, we implemented a solution where users can define those fields in the UI, but why reinvent the wheel when Helm already provided a way to specify this?\\n\\nCyclops controller reads the Helm chart and values schema. Then, it recursively traverses through all the fields in the schema and renders the field based on the field specification. It knows how to render a field based on the field type (`string`, `boolean`, `object`, `array`...), description of the field, field rules (e.g., minimum or maximum value), and many more.\\n\\n![Untitled](../../static/img/2023-11-13-JSON-schemas/JSON-to-UI.png)\\n\\nNow that the UI is rendered, a user of Cyclops can click through the form and fill in those fields. Thanks to the schema, values entered by a developer will now always conform to the schema since the UI won\u2019t let you specify any fields (e.g., allow you typos in field names) or set the number of replicas to `three` instead of `3`. This is an exaggerated example, but you can probably see the point. The UI will take care of validating your input, and you will have clear guidelines on how to configure your service.\\n\\nOnce values are entered and saved in the UI, they are passed to the Helm templating engine and the templates from the `/templates` folder. This results in all Kubernetes resources being configured for the needs of each team/developer without getting into specific implementation details of each resource.\\n\\n![Untitled](../../static/img/2023-11-13-JSON-schemas/UI-to-K8s.png)\\n\\n## Final thoughts\\n\\nHope this blog post helped you understand how the rendering part of Cyclops works and demystified the whole project. We briefly touched on [Helm](https://helm.sh/docs/) and [JSON schema](https://json-schema.org/), but both are larger pieces of software that we can\'t describe in such a short blog post, so we encourage you to check their documentation."},{"id":"welcome","metadata":{"permalink":"/blog/welcome","source":"@site/blog/2023-10-29-welcome/index.md","title":"Welcome","description":"Hi all!","date":"2023-10-29T00:00:00.000Z","formattedDate":"October 29, 2023","tags":[],"readingTime":0.525,"hasTruncateMarker":false,"authors":[{"name":"Petar Cvitanovi\u0107","title":"Cyclops CTO","url":"https://github.com/petar-cvit","imageURL":"https://github.com/petar-cvit.png","key":"petarc"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["petarc"]},"unlisted":false,"prevItem":{"title":"How Cyclops utilizes JSON schema to deliver dynamical UI","permalink":"/blog/2023/11/13/JSON-schemas"}},"content":"Hi all!\\n\\nWe are launching a blog post series on topics relevant to people following our startup journey. From technical topics \\nlike building high availability apps in Kubernetes to nontechnical ones, like our experience in some of the accelerators\\nwe have been through.\\n\\nOverall, we hope you will enjoy the content, and of course, you are more than encouraged to propose some topics you \\nwould like to see here on our Discord.\\n\\nAlso, if you are interested in contributing to our project, you can find open issues on our GitHub repository, and while\\nyou are there, give it a star :star:\\n\\n**Blog posts coming soon...**"}]}')}}]);