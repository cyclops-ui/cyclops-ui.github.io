"use strict";(self.webpackChunkcyclops_ui_docs=self.webpackChunkcyclops_ui_docs||[]).push([[477],{10:e=>{e.exports=JSON.parse('{"blogPosts":[{"id":"/2024/1/3/cyclops-overview","metadata":{"permalink":"/blog/2024/1/3/cyclops-overview","source":"@site/blog/2024-1-3-cyclops-overview/index.md","title":"Kubernetes Made Simple - Introducing Cyclops","description":"Modules in Cyclops","date":"2024-01-03T00:00:00.000Z","formattedDate":"January 3, 2024","tags":[],"readingTime":6.795,"hasTruncateMarker":false,"authors":[{"name":"Juraj Karad\u017ea","title":"Cyclops CEO","url":"https://github.com/KaradzaJuraj","imageURL":"https://github.com/KaradzaJuraj.png","key":"jurajk"}],"frontMatter":{"title":"Kubernetes Made Simple - Introducing Cyclops","authors":["jurajk"]},"unlisted":false,"nextItem":{"title":"Complexity by Simplicity - A Deep Dive Into Kubernetes Components","permalink":"/blog/2023/12/18/k8s-cluster-components"}},"content":"![Modules in Cyclops](../../static/img/2024-1-3-cyclops-overview/cyclops_overview_1.png)\\n\\nIf you are a developer, the chances are you have heard about Kubernetes. You heard that it is an amazing tool to help \\nyou scale your applications and manage your micro-services. But, you probably also heard that it is **VERY** complex. \\nIt is so complex that you were probably scared off. And I don\u2019t blame you; that is the first reaction I got as well.\\n\\nIf you search the top posts with the Kubernetes tags on this website, you will find a myriad of tutorials and people \\nexplaining Kubernetes. These posts are the most trending because people **WANT** to understand Kubernetes because we \\nfeel like, in today\'s software development world, Kubernetes is unavoidable. And this is true, to an extent\u2026\\n\\nSoftware developers are often required to understand and work with Kubernetes; if you have ever looked for jobs in this \\nsector, you know this already. But what if there was a tool to minimize your touching points with Kubernetes? A tool \\nthat simplifies the process and gives you guidance when trying to deploy applications into Kubernetes clusters. A tool \\nthat is highly customizable and lets someone in your organization (who understands Kubernetes, commonly known as a \\nDevOps) create a user interface for you!\\n\\nYep, you guessed it, it\u2019s Cyclops! \ud83d\ude04\\n\\nAnd just to clarify, Cyclops is not used to create and manage Kubernetes clusters and other infrastructure; rather, \\nCyclops is used for deploying and managing applications INSIDE the cluster.\\n\\n### Show us your support \ud83d\ude4f\ud83c\udffb\\n\\nWe are building Cyclops to be **open-source**, and your support would mean the world to us. Consider giving us a star \\non [GitHub](https://github.com/cyclops-ui/cyclops) and following us on [ProductHunt](https://www.producthunt.com/products/cyclops), where we scheduled our very \\nfirst release!\\n\\n## Before we start\\n\\nIn order to test out Cyclops, you are going to need a few things. If this is not your first time using Kubernetes, the \\nchances are you already have everything ready, but we will still describe each of the components for the newcomers to \\nthe Kubernetes space. These tools are not only used for Cyclops, and you can use them for anything Kubernetes-related.\\n\\nThe main thing you are going to need to test out Cyclops is a Kubernetes cluster. If you have one that you can use to \\nplay with, great; if not, we will show you how to spin up a cluster on your own computer. So, the three prerequisites \\nfor doing this are:\\n\\n1. [**1. Docker**](https://www.docker.com/products/docker-desktop/)\\n2. [**2. Minikube**](https://minikube.sigs.k8s.io/docs/)\\n3. [**3. kubectl**](https://kubernetes.io/docs/tasks/tools/)\\n\\nDocker is the most popular containerization tool, and we will use it to download and spin up a Minikube image. \\nDownloading Docker is straightforward: go to their webpage and download the Docker Desktop application.\\n\\nMinikube plays the role of a Kubernetes cluster on your local machine. It is a great tool for developing and \\ntesting out your Kubernetes applications, and it is perfect for this scenario. You can find a guide on how to install \\nit [here](https://minikube.sigs.k8s.io/docs/start/).\\n\\nThe final thing missing is a way of communicating with your Kubernetes cluster, and this is done through the Kubernetes \\ncommand line tool called `kubectl`. It can be used to deploy applications, inspect and manage cluster resources, and \\nview logs. In this tutorial, we will use it to install Cyclops into our cluster on Minikube and expose its \\nfunctionality outside the cluster.\\n\\n## Installing Cyclops\\n\\nOnce you have your Kubernetes cluster ready (check the *Before We Start* section), installing Cyclops is a \\nstraightforward process. Using `kubectl`, run the following command in your terminal:\\n\\n```\\nkubectl apply -f https://raw.githubusercontent.com/cyclops-ui/cyclops/v0.0.1-alpha.5/install/cyclops-install.yaml\\n```\\n\\nIt will create a new namespace called `cyclops` and deploy everything you need for your Cyclops instance to run.\\n\\nNow, all that is left is to expose the Cyclops server outside the cluster. You will need to expose both the backend and \\nfrontend with the commands below.\\n\\nExpose frontend through:\\n\\n```\\nkubectl port-forward svc/cyclops-ui 3000:3000 -n cyclops\\n```\\n\\nAnd the backend through:\\n\\n```\\nkubectl port-forward svc/cyclops-ctrl 8080:8080 -n cyclops\\n```\\n\\nAnd that\'s it! You can now access Cyclops in your browser at [http://localhost:3000](http://localhost:3000/).\\nIf you are having trouble with the `port-forward` commands, you probably just need to wait a few of seconds after \\ninstalling Cyclops into your cluster, it can take a while to start all it\u2019s resources.\\n\\n## It\u2019s Demo Time \ud83d\udca5\\n\\nNow that you have your Cyclops instance up and running, it\u2019s time to see what it\u2019s capable of.\\n\\nYou should be greeted with an almost empty screen with no deployed modules showing. *Module* is Cyclops\u2019s slang for \\napplication \ud83d\ude0e. So, let\u2019s start by creating our first module!\\n\\nBy clicking on the *Add module* button in the top right corner, you should be taken to a new screen. Here, Cyclops asks \\nus which Helm chart do we want to deploy.\\n\\nNot to go too deep, but [Helm](https://helm.sh/) is a very popular open-source package manager for Kubernetes. It helps \\nyou create configuration files that are needed for applications running in Kubernetes. These charts let Kubernetes know \\nhow to handle your application in the cluster.\\n\\nDon\u2019t worry; to showcase the basics of Cyclops, we created a simple Helm chart so that anyone can follow along. You can \\nfind what it looks like in our [GitHub repository](https://github.com/cyclops-ui/templates/tree/main/demo), along with \\na couple of more examples of Helm charts that you can use!\\n\\n![Loaded Chart](../../static/img/2024-1-3-cyclops-overview/cyclops_overview_2.png)\\n\\nAs you can see, once you enter the repository of your chart, Cyclops will render a user interface.  *If you want to \\nfind out the magic behind the rendering, check out our previous \\n[blog](https://dev.to/cyclops-ui/how-cyclops-utilizes-json-schema-to-deliver-dynamical-ui-49e).*\\n\\nYou can fill out the fields as you wish, but be mindful of \\n[the Kubernetes naming conventions](https://kubernetes.io/docs/concepts/overview/working-with-objects/names/)!\\n\\nIf you want to follow along, my input is as follows:\\n\\n```\\nname: demo\\nreplicas: 1\\nimage: nginx\\nversion: 1.14.2\\nservice: true\\n```\\n\\nWe will set the module name to `demo` as well. Click save, and Cyclops will show you the details of your new module.\\n\\n![Single pod Deployment](../../static/img/2024-1-3-cyclops-overview/cyclops_overview_3.png)\\n\\nThis screen shows you all the resources your application is using at the moment. It will list all the deployments, \\nservices, pods, or any other resource. Here, we can see that Cyclops deployed one pod into your cluster, as we specified \\nin the replicas field. If you want to make sure that it really is running in your cluster, you can check it out by using \\nthe following `kubectl` command:\\n\\n```\\nkubectl get pods\\n```\\n\\nBut what if all of a sudden, there was a need to scale up your application or any other resource? Well, don\'t worry; \\nwith Cyclops, it\u2019s really easy!\\n\\nBy clicking the *Edit* button, you can change the values of your application\u2019s resources. Let\u2019s try to scale our \\napplication up to 3 replicas and see what happens.\\n\\n![Three pod Deployment](../../static/img/2024-1-3-cyclops-overview/cyclops_overview_4.png)\\n\\nYou should now see two more pods in the *Deployment* tab; hurray! \ud83c\udf89\\n\\nOf course, this works for any other change you might want to make to your application. Like, the service, perhaps? What \\nif we realized we don\'t really need it anymore? Well, with Cyclops, it\'s really easy to shut it down if need be.\\n\\nClick again on the *Edit* button, and this time, turn off the service toggle.\\n\\n![Service shut down](../../static/img/2024-1-3-cyclops-overview/cyclops_overview_5.png)\\n\\nCyclops won\'t delete it automatically but will warn you (via the warning triangle sign) that you shut it down, and it is \\nnot in function anymore. This means you can safely delete it!\\n\\nAnd if you are sick and tired of your application, you can delete the whole thing as well \ud83d\uddd1\ufe0f\\n\\nClick on the Delete button and fill in the name of the module to safely delete it. You can, again, check if it really \\nwas deleted with `kubectl`:\\n\\n```\\nkubectl get pods\\n```\\n\\n## Finish\\n\\nAnd that\u2019s all there really is to it! Cyclops allows people with varying knowledge of Kubernetes to leverage its power. \\nIf you followed this tutorial, you should have deployed your very first application using Cyclops; congratz! \ud83c\udf89 On our \\n[webpage](https://cyclops-ui.com/), you can find one more tutorial showcasing more features and a more complicated use \\ncase, as well as our contact and community info.\\n\\nIf you have any sort of feedback or ideas on how to make Cyclops better, you can fill out our short \\n[Google form](https://forms.gle/jrwcBHRtpwmK91v47)!"},{"id":"/2023/12/18/k8s-cluster-components","metadata":{"permalink":"/blog/2023/12/18/k8s-cluster-components","source":"@site/blog/2023-12-18-k8s-cluster-components/index.md","title":"Complexity by Simplicity - A Deep Dive Into Kubernetes Components","description":"Image of a Kubernetes cluster based on an image found on https://kubernetes.io/docs/concepts/overview/components/","date":"2023-12-18T00:00:00.000Z","formattedDate":"December 18, 2023","tags":[],"readingTime":8.34,"hasTruncateMarker":false,"authors":[{"name":"Juraj Karad\u017ea","title":"Cyclops CEO","url":"https://github.com/KaradzaJuraj","imageURL":"https://github.com/KaradzaJuraj.png","key":"jurajk"}],"frontMatter":{"title":"Complexity by Simplicity - A Deep Dive Into Kubernetes Components","authors":["jurajk"]},"unlisted":false,"prevItem":{"title":"Kubernetes Made Simple - Introducing Cyclops","permalink":"/blog/2024/1/3/cyclops-overview"},"nextItem":{"title":"Five Kubernetes Development Tools for Efficient Cluster Management","permalink":"/blog/2023/12/08/five-kubernetes-tools"}},"content":"![Image of a Kubernetes cluster based on an image found on https://kubernetes.io/docs/concepts/overview/components/](../../static/img/2023-12-18-k8s-cluster-components/k8s_cluster.png)\\n\\n# Intro\\n\\nA couple of days ago, I held a talk about Kubernetes and its components at the college I used to go to. My mom said she liked the talk, so I turned it into a blog post.\\n\\nMany software engineers tend to look away from anything related to Kubernetes, even though they might use it daily. At first glance, it seems complex and like a whole new world to dive into. And yeah, it is, but in this blog post, I will go over all of the main components of a Kubernetes cluster and explain what they do in an example.\\n\\nBy the end of the blog post, you won\'t be a Kubernetes expert, but you will probably get a good idea of what to look for and how to structure the chaos that Kubernetes seems to be at first.\\n\\n### **Show us your support \ud83d\ude4f\ud83c\udffb**\\n![Github Stars](../../static/img/2023-12-18-k8s-cluster-components/github_stars.gif)\\n\\nBefore we start, we would love it if you starred our repository and helped us get our tool in front of other developers. Our GitHub repo is here:\xa0https://github.com/cyclops-ui/cyclops\xa0\u2b50\\n\\n# Components\\n\\nFirst of all, we can divide a Kubernetes cluster into two parts: **control plane** and **worker nodes**. The control plane takes care of the whole operation and controls the state of our cluster. We\u2019ll get into what that means shortly. On the other side, our worker nodes are essentially just computers listening to what the control plane tells them to do. They are the computing power of our cluster. Any application we run in the cluster will run on those nodes.\\n\\nLet\u2019s decompose that further.\\n\\n## Control plane\\n\\n![Control Plane](../../static/img/2023-12-18-k8s-cluster-components/control_plane.png)\\n\\nAs we said, the control plane is making sure our cluster is running as expected. It does that by communicating with the cluster user, scheduling workloads, managing cluster state and so on.\\n\\nThe control plane is made of four crucial components. Simple by themselves, but together, they create a complex system. These components are: \\n\\n1. **1. API**\\n2. **2. ETCD**\\n3. **3. Scheduler**\\n4. **4. Controller Manager**\\n\\nControl plane components can be run on any machine in the cluster, but are usually run on a separate set of machines, often called **master nodes**. Those machines are not used to run any other container or application and are reserved for the Kubernetes control plane.\\n\\n### API\\n\\nThe Kubernetes API acts as the cluster\'s front-end interface, allowing users to interact with the cluster, define desired states, and perform operations such as creating, updating, and deleting resources.\\n\\nIt is the **only point of contact** we have with the cluster. Also, no other components are talking directly to each other, but all communication is happening **through** the API.\\n\\n### ETCD\\n\\nETCD is the API\u2019s **database**; it\'s as simple as that. When you tell Kubernetes to create a deployment, it gets stored in the ETCD alongside all the other created resources.\\n\\nOne characteristic of ETCD is that its key-value storage is organized as a filesystem. Another great feature of ETCD is that users can **subscribe** to events and get notified about changes. For example, *let me know when a new pod gets created*.\\n\\n### Scheduler\\n\\nAs the name suggests, the scheduler **decides which node a pod will run on**. It does that by a set of rules you can read in the [Kubernetes documentation](https://kubernetes.io/docs/home/). *This is what I meant when I said you won\'t be an expert, but you will know what to google :)*  \\n\\nThe Scheduler **subscribes** to all newly created pods saved in ETCD, but it can **only** talk with the API to get this update.\\n\\nWhen it catches that a pod has been created, it calculates which worker node to run it on. Once it\'s made up its mind, **the scheduler doesn\'t run anything on any machine**; it just tells the API to run the pod on a particular node.\\n\\n### Controller Manager\\n\\nThe last component from the control plane is the controller manager. We can take it as a thermostat for our cluster. Its job is to shift the current state of the cluster to the desired state.\\n\\nThis means that it will **create all the needed resources** under the hood to satisfy our needs and get our applications up and running.\\n\\nIt runs multiple controller processes subscribed to changes on the ETCD, compiled into the same binary for easier deployment. Controller managers\u2019 roles and what those controllers do will be defined more closely later in the blog.\\n\\n## Worker nodes\\n\\n![Worker nodes](../../static/img/2023-12-18-k8s-cluster-components/nodes.png)\\n\\nNow that we have concluded what manages the whole cluster, let\'s dive into where our containers are running and how that is achieved.\\n\\nThere are 3 components running on each node in a Kubernetes cluster. Of course, you can have multiple nodes in a cluster, but each needs these three components to host your applications.\\n\\nThose being:\\n\\n1. **1. container runtime**\\n2. **2. kubelet**\\n3. **3. kube proxy**\\n\\n### Container runtime\\n\\nThe component that allows Kubernetes to run containers and manages the lifecycle of a container on a node is the container runtime.\\n\\nMultiple container runtimes are supported, like [conatinerd](https://containerd.io/), [cri-o](https://cri-o.io/), or other [CRI compliant runtimes](https://github.com/kubernetes/community/blob/master/contributors/devel/sig-node/container-runtime-interface.md).\\n\\n### Kubelet\\n\\nAnother component subscribed to pod events is Kubelet. Each time a pod is scheduled on a node, the Kubelet running on that node will hear that and start all defined containers. On top of that, Kubelet also performs health checks to ensure everything is running as expected.\\n\\n### Kube proxy\\n\\nKubeProxy in Kubernetes manages network connectivity between pods across the cluster, handling tasks like load balancing and network routing. It ensures seamless communication among pods by maintaining network rules and translating service abstractions into actionable network policies.\\n\\n# From a deployment to a running container\\n\\nNow that we have listed all of the components and their role in a Kubernetes cluster, let\'s tell a story on how a Kubernetes Deployment becomes a set of containers running on various machines across the cluster.\\n\\n## Pods, Replicasets and Deployments\\n\\nJust a quick reminder on the relation of these three: Pods, Replicasets, and Deployments.\\n\\n![Deployment components](../../static/img/2023-12-18-k8s-cluster-components/deployment_components.png)\\n\\nThe smallest unit we can deploy in a Kubernetes cluster is a **pod**. With it, we are going to define our containers.\\n\\nMost likely, we will need a couple of instances of the same application, and we can define how to replicate our pods with a **Replicaset**. It will ensure that we have the desired number of pods running by starting and terminating them.\\n\\nCool, now we have our application replicated, but we would like to roll out a new version of our application. We have to tear down existing Pods/Replicaset and create new ones. A Deployment will automate this process, allowing us to roll out our feature safely.\\n\\n## The Prestige\\n\\n![Prestige](../../static/img/2023-12-18-k8s-cluster-components/prestige_gif.gif)\\n\\nNow that we have all our terminology and touched on all Kubernetes components and their role, let\'s see what happens when we \u201capply\u201d a Deployment to a Kubernetes cluster.\\n\\nLet\'s say that we have created a `deployment.yaml` file defining our application (you can see how to do that [here](https://imgur.com/7qKp189)) and ran `kubectl apply -f deployment.yaml`. `kubectl` will now submit our deployment definition to our cluster\'s **only point of contact** - the Kubernetes API.\\n\\nOur simple API will store our deployment in the ETCD database. Each time a Deployment object is saved into ETCD, it will let the API know that there was a change on Deployments and that it should let **everybody who is subscribed** to such an event know about it.\\n\\nAnd there is a component in the control plane that would like to know when a new Deployment spawns, and that\'s the **Controller Manager**. When it hears about a new Deployment, it will create a new Replicaset based on the Deployment configuration. To make this Replicaset, it will call the API with a create request.\\n\\nCreating a Replicaset is much like creating a Deployment. API will receive a Replicaset to create and store into ETCD. This will make ETCD tell the API that somebody created a Replicaset and pass that information to all subscribed components, which is **again** the Controller Manager.\\n\\nWhen the Controller Manager hears about the new Replicaset, it will create all the Pods defined with the Replicaset by, you guessed it, calling the API, which will store all those Pods into ETCD.\\n\\n![ As we said, a lot of things happened, so we decided to create a GIF that might help you understand the whole process under the hood.](../../static/img/2023-12-18-k8s-cluster-components/gif_k8s_final.gif)\\n\\n *As we said, a lot of things happened, so we decided to create a GIF that might help you understand the whole process under the hood.*\\n\\nHere, we include the Scheduler, which is subscribed to the Pod creation event. Each time it hears about a new Pod, it decides on which node it should be run. The Scheduler is not running the Pod but **only telling the API** which node it chose for it. The API will then save that information.\\n\\nAnother component listening to Pod events is the Kubelet, a component running on each worker node in the Kubernetes cluster. Each time the API tells the Kubelet that the Scheduler decided to run the Pod on its node, the Kubelet **will start all the containers** defined by the Pod.\\n\\nFinally, we turned our configuration into an application running on a machine! It is a lengthy process with many moving parts, but this may be my favorite part.\\n\\nEach component takes just a tiny bit of the responsibility of deploying an application, but they solve a pretty complex problem together.\\n\\n# Final thoughts\\n\\nHope this article helped you get a grasp on Kubernetes components and helped you demystify the most popular orchestrator out there. We encourage you to dig around yourself because we enjoyed learning about this.\\n\\nOne book we recommend to learn about Kubernetes is \u201cKubernetes in action\u201d by Marko Luk\u0161a. It is pretty popular and gives an excellent overview of what is going on under the hood of Kubernetes and how to use it."},{"id":"/2023/12/08/five-kubernetes-tools","metadata":{"permalink":"/blog/2023/12/08/five-kubernetes-tools","source":"@site/blog/2023-12-08-five-kubernetes-tools/index.md","title":"Five Kubernetes Development Tools for Efficient Cluster Management","description":"kubernetes tools","date":"2023-12-08T00:00:00.000Z","formattedDate":"December 8, 2023","tags":[],"readingTime":7.065,"hasTruncateMarker":false,"authors":[{"name":"Juraj Karad\u017ea","title":"Cyclops CEO","url":"https://github.com/KaradzaJuraj","imageURL":"https://github.com/KaradzaJuraj.png","key":"jurajk"}],"frontMatter":{"title":"Five Kubernetes Development Tools for Efficient Cluster Management","authors":["jurajk"]},"unlisted":false,"prevItem":{"title":"Complexity by Simplicity - A Deep Dive Into Kubernetes Components","permalink":"/blog/2023/12/18/k8s-cluster-components"},"nextItem":{"title":"How Cyclops utilizes JSON schema to deliver dynamical UI","permalink":"/blog/2023/11/13/JSON-schemas"}},"content":"![kubernetes tools](../../static/img/2023-12-08-five-kubernetes-tools/kubernetes_tools.png)\\n\\nKubernetes has become the go-to platform for managing containerized applications, offering scalability, flexibility, and robustness. However, the complexity of Kubernetes can be daunting, requiring developers and DevOps teams to navigate through intricate configuration files and command-line interactions. \\n\\nSeveral powerful development tools have emerged to simplify the management of Kubernetes clusters and streamline the deployment process. In this article, we will explore five Kubernetes development tools: \\n\\n1. [**1. Prometheus**](https://prometheus.io/)\\n2. [**2. Cyclops**](https://cyclops-ui.com/)\\n3. [**3. Keda**](https://keda.sh/)\\n4. [**4. Karpenter**](https://karpenter.sh/)\\n5. [**5. Velero**](https://velero.io/)\\n\\nThese tools offer intuitive user interfaces, automated scaling capabilities, disaster recovery solutions, and improved efficiency in managing Kubernetes clusters.\\n\\n### Show us your support \ud83d\ude4f\ud83c\udffb\\n\\nBefore we start, we would love it if you starred our repository and helped us get our tool in front of other developers. Our GitHub repo is here: https://github.com/cyclops-ui/cyclops \u2b50\\n\\n## 1. Prometheus: Monitoring and Alerting for Kubernetes\\n![Prometheus logo](../../static/img/2023-12-08-five-kubernetes-tools/prometheus_logo.png)\\n\\n**Prometheus** is an open-source monitoring and alerting toolkit designed specifically for microservices and containers. It offers flexible querying, real-time notifications, and visibility into containerized workloads, APIs, and distributed services. \\n\\nOne of the features of Prometheus is its ability to assist with cloud-native security by detecting irregular traffic or activity that could potentially escalate into an attack.\\n\\nIt uses a pull-based system, sending HTTP requests called \\"scrapes\\", to collect metrics from applications and services. These metrics are stored in memory and on local disk, allowing for easy retrieval and analysis.\\n\\nPrometheus can access data directly from client libraries or through exporters, which are software located adjacent to the application. Exporters accept HTTP requests from Prometheus, ensure the data format compatibility, and serve the requested data to the Prometheus server.\\n\\nPrometheus provides four main types of metrics: Counter, Gauge, Histogram, and Summary. These metrics offer flexibility in measuring various aspects of applications and services, such as event start counts, memory usage, data aggregation, and quantile ranges.\\n\\nTo discover targets for monitoring, Prometheus utilizes service discovery in Kubernetes clusters. It can access machine-level metrics separately from application information, allowing for comprehensive monitoring.\\n\\nOnce the data collection is complete, Prometheus provides a query language called PromQL, which enables users to access and export monitoring data to graphical interfaces like Grafana or send alerts using Alertmanager.\\n\\n## 2. Cyclops: Deploying applications with just a couple of clicks\\n\\n![Cyclops logo](../../static/img/2023-12-08-five-kubernetes-tools/cyclops_logo.png)\\n\\n**Cyclops** is a tool that simplifies the management of applications running in Kubernetes clusters. It abstracts complex configuration files into form-based UIs, eliminating the need for manual configuration and command-line interactions. This makes the deployment process more accessible to individuals with varying levels of technical expertise.\\n\\nWith Cyclops, you\'re not boxed into a one-size-fits-all approach. You can customize modules to suit your unique needs, giving you the freedom to create templates with input validation for seamless collaboration with your team. \\n\\nThis not only speeds up your work but also empowers each team member to work independently, promoting a smoother and more efficient workflow.\\n\\nIn Cyclops, every module lays out a detailed list of resources it uses\u2014deployments, services, pods, and others, all in plain view. You can easily track their status, helping you quickly spot and fix any hiccups in your application. It\'s like having a clear roadmap to navigate and troubleshoot any issues that pop up.\\n\\nWithin the architecture of Cyclops, a central component is the [Helm](https://helm.sh/) engine, which allows the dynamic generation of configurations. This engine serves as a key mechanism for efficiently managing settings and parameters in the Cyclops framework.\\n\\nAs Kubernetes-based systems commonly employ Helm as their package manager, seamlessly integrating Cyclops is a straightforward process.\\n\\nCyclops promotes consistency and standardization in deployment practices. By providing predefined templates or configuration presets, Cyclops ensures that deployments adhere to established best practices and guidelines. This consistency not only improves the reliability and stability of deployments but also facilitates collaboration.\\n\\n## 3. Keda: Event-Driven Autoscaling for Kubernetes Workloads\\n\\n![Keda logo](../../static/img/2023-12-08-five-kubernetes-tools/keda_logo.png)\\n\\nKubernetes Horizontal Pod Autoscaling (HPA) and Vertical Pod Autoscaling (VPA) are widely used for autoscaling Kubernetes clusters based on CPU and memory usage. \\n\\nHowever, they have limitations, such as the inability to scale pods to zero or scale based on metrics other than resource utilization. This is where **Keda** (Kubernetes Event-Driven Autoscaling) comes into play.\\n\\nKeda is an open-source container autoscaler that extends the capabilities of native Kubernetes autoscaling solutions by scaling pods based on external events or triggers.\\n\\nMonitoring event sources like AWS SQS, Kafka, and RabbitMQ, Keda efficiently triggers or halts deployments based on predefined rules. This adaptable solution also allows for custom metrics, facilitating effective autoscaling tailored for message-driven microservices, ensuring optimal performance and resource utilization.\\n\\nThe components of Keda include event sources, scalers, metrics adapters, and controllers. Event sources provide the external events that trigger scaling, while scalers monitor these events and fetch metrics. Metrics adapters translate the metrics for the controller, which then scales the deployments accordingly.\\n\\nBy leveraging Keda, DevOps teams can free up resources and reduce cloud costs by scaling down when there are no events to process. Keda also offers interoperability with various DevOps toolchains, supporting both built-in and external scalers. \\n\\nWith Keda, autoscaling becomes more flexible and efficient, empowering teams to optimize resource utilization and adapt to changing workload requirements.\\n\\n## 4. Karpenter: Automated Node Provisioning for Kubernetes\\n\\n![Karpenter logo](../../static/img/2023-12-08-five-kubernetes-tools/karpenter_logo.png)\\n\\nKubernetes clusters often face the challenge of scheduling pods on available nodes. **Karpenter** is an open-source cluster auto scaler that automatically provisions new nodes in response to un-schedulable pods. It evaluates the aggregate resource requirements of pending pods and selects the optimal instance type to accommodate them. \\n\\nKarpenter also supports a consolidation feature, actively moving pods and replacing nodes with cheaper versions to reduce cluster costs.\\n\\nA standout feature is the introduction of \\"Node Pools,\\" allowing users to categorize nodes based on various criteria. This customization ensures a tailored approach to resource allocation, with Karpenter dynamically provisioning nodes into the most fitting pools.\\n\\nAt its core, Karpenter is designed to automate the scaling of Kubernetes clusters seamlessly. Leveraging Custom Resource Definitions (CRDs) within Kubernetes, Karpenter integrates seamlessly with existing tools and APIs, providing a familiar experience for users. \\n\\nThe flexibility of Karpenter extends beyond the confines of AWS, making it a versatile solution for both cloud and on-premises environments.\\n\\nKarpenter\'s adaptability shines through its support for user-defined strategies and policies through Kubernetes resources. This flexibility enables organizations to align Karpenter with their unique application and workload requirements, enabling better automated and optimized Kubernetes scalability.\\n\\n## 5. Velero: Disaster Recovery and Backup for Kubernetes\\n![Velero logo](../../static/img/2023-12-08-five-kubernetes-tools/velero_logo.png)\\n\\n**Velero** is a powerful tool that provides disaster recovery and backup solutions for Kubernetes clusters. It enables users to easily backup, restore, and migrate applications and their persistent volumes.\\n\\nVelero takes snapshots of cluster resources and data, storing them in object storage providers like AWS S3, Google Cloud Storage, or Azure Blob Storage.\\n\\nWith Velero, users can create backup schedules, ensuring regular snapshots of critical cluster resources. This allows for efficient disaster recovery in case of data loss or cluster failures. Velero also supports cluster migration, simplifying the process of moving applications and data between Kubernetes clusters.\\n\\nThe tool offers resource filtering capabilities, allowing users to selectively backup and restore specific resources.\\n\\nThis flexibility ensures that only relevant data is included in the backup, saving storage space and reducing backup and restore times. Velero integrates with CSI (Container Storage Interface), providing support for backing up volumes and restoring them to their original state.\\n\\nIn addition to disaster recovery and backup, Velero provides features like running in any namespace, extending functionality with hooks, and supporting custom plugins for enhanced customization. It offers troubleshooting guides for diagnosing and resolving common issues, ensuring a smooth experience in managing Kubernetes clusters.\\n\\n## Conclusion\\n\\nThese five Kubernetes development tools - Prometheus, Cyclops, Keda, Karpenter, and Velero - play pivotal roles in simplifying the complexities of Kubernetes cluster management.\\n\\nFrom monitoring and alerting with Prometheus to event-driven autoscaling using Keda, and automated node provisioning through Karpenter, each tool addresses specific challenges, contributing to more efficient and resilient Kubernetes environments.\\n\\nCyclops stands out for its user-friendly approach, abstracting complex configurations into intuitive UIs, while Velero provides crucial disaster recovery and backup solutions for safeguarding critical data and applications.\\n\\nAs Kubernetes continues to be a cornerstone in modern application deployment, these tools empower developers and DevOps teams to navigate the intricacies of containerized environments with greater ease.\\n\\nBy integrating these tools into your Kubernetes workflows, you can enhance scalability, streamline deployment processes, and ensure the robustness of your applications in today\'s dynamic and demanding computing landscape."},{"id":"/2023/11/13/JSON-schemas","metadata":{"permalink":"/blog/2023/11/13/JSON-schemas","source":"@site/blog/2023-11-13-JSON-schemas/index.md","title":"How Cyclops utilizes JSON schema to deliver dynamical UI","description":"Cyclops turns complicated YAML manifests into simple and structured UIs where developers can click away their Kubernetes application configuration.","date":"2023-11-13T00:00:00.000Z","formattedDate":"November 13, 2023","tags":[],"readingTime":3.725,"hasTruncateMarker":false,"authors":[{"name":"Petar Cvitanovi\u0107","title":"Cyclops CTO","url":"https://github.com/petar-cvit","imageURL":"https://github.com/petar-cvit.png","key":"petarc"}],"frontMatter":{"title":"How Cyclops utilizes JSON schema to deliver dynamical UI","authors":["petarc"]},"unlisted":false,"prevItem":{"title":"Five Kubernetes Development Tools for Efficient Cluster Management","permalink":"/blog/2023/12/08/five-kubernetes-tools"},"nextItem":{"title":"Welcome","permalink":"/blog/welcome"}},"content":"Cyclops turns complicated YAML manifests into simple and structured UIs where developers can click away their Kubernetes application configuration.\\n\u201dGreat! But how does it know how to render this UI? Should I implement a UI form each time I need a new set of fields to configure? I don\u2019t know React! I don\u2019t know frontend!\u201c\\n\\nThis blog post should cure your anxiety about implementing a UI for each type of application and explain how Cyclops knows what to render so you can deploy to your K8s cluster carefree.\\n\\nTo better understand how Cyclops renders the UI, we will scratch the surface of Helm, which Cyclops uses as its templating engine.\\n\\n## A bit about Helm\\n\\nHelm is a Kubernetes package manager that helps deploy and manage Kubernetes resources by packing them into charts. It also has a templating engine that allows developers to configure their apps depending on the specific values injected into the helm template.\\n\\nThe usual Helm chart structure is as follows:\\n\\n```bash\\n\u251c\u2500\u2500 Chart.yaml\\n\u251c\u2500\u2500 templates\\n\u2502   \u251c\u2500\u2500 deployment.yaml\\n\u2502   \u2514\u2500\u2500 service.yaml\\n\u251c\u2500\u2500 values.schema.json\\n\u2514\u2500\u2500 values.yaml\\n```\\n\\n> A few other Helm chart parts are left out on purpose since they are not tangible to the rest of the blog. You can read more about each of those in [Helm\u2019s official documentation](https://helm.sh/docs/topics/charts/)\\n\\n- `Chart.yaml` - A YAML file containing information about the chart (like name, version\u2026)\\n- `templates` - A directory of templates that, when combined with values, will generate valid Kubernetes manifest files\\n- `values.yaml` - The default configuration values for this chart\\n- `values.schema.json` - A JSON Schema for imposing a structure on the `values.yaml` file\\n\\nWhen using Helm, you can change your `values.yaml` however you see fit for your application. The problem is that you can change them __however__ you like, which allows you to misconfigure some parts of your application because you misspelled a field or messed up indentation in the `values.yaml`.\\n\\nHere is where [JSON schema](https://json-schema.org) from the `values.schema.json` comes in. It will define which fields you should set and even to which values (e.g., you can specify that a field called replicas can\u2019t be set to lower than 0). Helm won\u2019t let you render a Kubernetes manifest with values that don\u2019t comply with the schema. There is an example of such schema later in the blog, but you can also check it out on [Helms official docs](https://helm.sh/docs/topics/charts/#schema-files)\\n\\n## Helm values schema and Cyclops UI\\n\\nNow that the schema\'s purpose in a Helm chart is explained let\u2019s get into how Cyclops uses it.\\n\\nSince the primary purpose of the values schema is to describe what the Helm chart needs to render all the Kubernetes resources, we naturally decided to use it for rendering the UI. On the first iterations of Cyclops, we implemented a solution where users can define those fields in the UI, but why reinvent the wheel when Helm already provided a way to specify this?\\n\\nCyclops controller reads the Helm chart and values schema. Then, it recursively traverses through all the fields in the schema and renders the field based on the field specification. It knows how to render a field based on the field type (`string`, `boolean`, `object`, `array`...), description of the field, field rules (e.g., minimum or maximum value), and many more.\\n\\n![Untitled](../../static/img/2023-11-13-JSON-schemas/JSON-to-UI.png)\\n\\nNow that the UI is rendered, a user of Cyclops can click through the form and fill in those fields. Thanks to the schema, values entered by a developer will now always conform to the schema since the UI won\u2019t let you specify any fields (e.g., allow you typos in field names) or set the number of replicas to `three` instead of `3`. This is an exaggerated example, but you can probably see the point. The UI will take care of validating your input, and you will have clear guidelines on how to configure your service.\\n\\nOnce values are entered and saved in the UI, they are passed to the Helm templating engine and the templates from the `/templates` folder. This results in all Kubernetes resources being configured for the needs of each team/developer without getting into specific implementation details of each resource.\\n\\n![Untitled](../../static/img/2023-11-13-JSON-schemas/UI-to-K8s.png)\\n\\n## Final thoughts\\n\\nHope this blog post helped you understand how the rendering part of Cyclops works and demystified the whole project. We briefly touched on [Helm](https://helm.sh/docs/) and [JSON schema](https://json-schema.org/), but both are larger pieces of software that we can\'t describe in such a short blog post, so we encourage you to check their documentation."},{"id":"welcome","metadata":{"permalink":"/blog/welcome","source":"@site/blog/2023-10-29-welcome/index.md","title":"Welcome","description":"Hi all!","date":"2023-10-29T00:00:00.000Z","formattedDate":"October 29, 2023","tags":[],"readingTime":0.525,"hasTruncateMarker":false,"authors":[{"name":"Petar Cvitanovi\u0107","title":"Cyclops CTO","url":"https://github.com/petar-cvit","imageURL":"https://github.com/petar-cvit.png","key":"petarc"}],"frontMatter":{"slug":"welcome","title":"Welcome","authors":["petarc"]},"unlisted":false,"prevItem":{"title":"How Cyclops utilizes JSON schema to deliver dynamical UI","permalink":"/blog/2023/11/13/JSON-schemas"}},"content":"Hi all!\\n\\nWe are launching a blog post series on topics relevant to people following our startup journey. From technical topics \\nlike building high availability apps in Kubernetes to nontechnical ones, like our experience in some of the accelerators\\nwe have been through.\\n\\nOverall, we hope you will enjoy the content, and of course, you are more than encouraged to propose some topics you \\nwould like to see here on our Discord.\\n\\nAlso, if you are interested in contributing to our project, you can find open issues on our GitHub repository, and while\\nyou are there, give it a star :star:\\n\\n**Blog posts coming soon...**"}]}')}}]);